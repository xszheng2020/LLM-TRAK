{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44e0a8b-ddd3-46d2-8c91-cbbdb8f7c018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install peft==0.5.0\n",
    "\n",
    "# !pip install traker==0.1.3\n",
    "# !pip install fast-jl==0.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd023b35-0a86-45cb-8577-3f3dbbefd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "os.environ[\"HF_HOME\"]=\"~/.cache/huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e92ef4-c6cb-459e-9095-c68388f09c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74b0be4-12ee-4476-81d4-6e9eb856d682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import default_data_collator\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde76f89-825a-499b-8e2f-5e8d3e4e186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_id = \"chansung/gpt4-alpaca-lora-7b\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "config.base_model_name_or_path = 'baffo32/decapoda-research-llama-7B-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8869d8-29a0-4442-b1fd-ccab0146067f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type='LORA', auto_mapping=None, base_model_name_or_path='baffo32/decapoda-research-llama-7B-hf', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=16, target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj'], lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f8121-110f-473c-b5ee-30b3c06a9937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1de9e7-478d-49cf-96bc-a15576044ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9745ad32322f4ba4be9955175894e024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(config.base_model_name_or_path, \n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             low_cpu_mem_usage=True,\n",
    "                                            )\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, torch_dtype=torch.float16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ee5d45-195f-4fee-8769-36cc1d86ecdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 6,755,192,832 || trainable%: 0.0\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325ac4c3-2610-4934-b51f-61e0a910637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if 'lora' in n:\n",
    "        print(n)\n",
    "        p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c84ddcf-1dbd-46e5-9488-4fbbf85fbb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,777,216 || all params: 6,755,192,832 || trainable%: 0.24836028248556738\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c82d0-1dcc-4762-a93f-4d10bb058880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd8e51-8e6c-41f8-875b-4df0da6b9397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e9a12-4ba3-49ad-92fd-76f18f8672ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6bfa8c-73cd-43ab-ad77-a9059b689cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/alpaca_data_gpt4.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b284766b-d60f-46f3-847f-d30d97198f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 52002\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if data_path.endswith(\".json\") or data_path.endswith(\".jsonl\"):\n",
    "    dataset = load_dataset(\"json\", data_files=data_path)\n",
    "else:\n",
    "    dataset = load_dataset(data_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e2a9d-c071-4e4c-9467-01e3f2f08c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6585cc53-84aa-4678-950e-70997fc0484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prompter import Prompter\n",
    "\n",
    "prompt_template_name = 'alpaca'\n",
    "cutoff_len = 128\n",
    "\n",
    "prompter = Prompter(prompt_template_name)\n",
    "\n",
    "# data preprocessing\n",
    "tokenizer = LlamaTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "if True:\n",
    "    def tokenize(prompt, add_eos_token=True):\n",
    "        # there's probably a way to do this with the tokenizer settings\n",
    "        # but again, gotta move fast\n",
    "        result = tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=cutoff_len,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        ####\n",
    "        result[\"input_ids\"][-1] = tokenizer.eos_token_id\n",
    "        result[\"attention_mask\"][-1] = 1\n",
    "        ####\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def generate_and_tokenize_prompt(data_point):\n",
    "        full_prompt = prompter.generate_prompt(\n",
    "            data_point[\"instruction\"],\n",
    "            data_point[\"input\"],\n",
    "            data_point[\"output\"],\n",
    "        )\n",
    "        tokenized_full_prompt = tokenize(full_prompt)\n",
    "        \n",
    "        return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c49abe-dab6-4d30-8285-c2e4e651ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = dataset.map(\n",
    "    generate_and_tokenize_prompt,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6525bf2d-6e44-483d-b35b-141c2cfcb3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1064d62-299a-4ae7-a0cc-a3b916341e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "677bd1d7-ef2c-4d04-aa43-5529cf1aedae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = processed_datasets[\"train\"]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917d4a1-7b34-4a15-9342-0bf6a1da23a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bbd115b-bc29-48a4-ac95-94e2927db37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "            tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3bb602a-a891-457c-b741-c8e9d37c9550",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=False, collate_fn=data_collator, batch_size=batch_size, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a0f695-6afd-4f65-a571-11e96018377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0, 13866,   338,  ...,  9128,  6354,     0],\n",
      "        [    0, 13866,   338,  ...,     0,     0,     0],\n",
      "        [    0, 13866,   338,  ..., 17105,   411,     0],\n",
      "        ...,\n",
      "        [    0, 13866,   338,  ...,     0,     0,     0],\n",
      "        [    0, 13866,   338,  ...,  1716,   278,     0],\n",
      "        [    0, 13866,   338,  ..., 29892,   902,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[    0, 13866,   338,  ...,  9128,  6354,     0],\n",
      "        [    0, 13866,   338,  ...,  -100,  -100,  -100],\n",
      "        [    0, 13866,   338,  ..., 17105,   411,     0],\n",
      "        ...,\n",
      "        [    0, 13866,   338,  ...,  -100,  -100,  -100],\n",
      "        [    0, 13866,   338,  ...,  1716,   278,     0],\n",
      "        [    0, 13866,   338,  ..., 29892,   902,     0]])}\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcceee9-74c6-4cbd-8c78-f7783f8cc024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322baa30-546b-4a43-a688-53189959d4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b18028-8b30-4c85-afa5-9e3c47ac1d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7778fbb-d029-4d83-9b97-9d5850e6904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.func import functional_call, vmap, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d78b848-e72a-4ecd-b234-74b20e2fcbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(params, buffers, input_ids, attention_mask, labels):\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    attention_mask = attention_mask.unsqueeze(0)\n",
    "    labels = labels.unsqueeze(0)\n",
    "    \n",
    "    outputs = functional_call(model, (params, buffers), args=input_ids, \n",
    "                                  kwargs={'attention_mask': attention_mask, \n",
    "                                          # 'labels': labels\n",
    "                                         })\n",
    "    lm_logits = outputs.logits\n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "        # move labels to correct device to enable model parallelism\n",
    "        labels = labels.to(lm_logits.device)\n",
    "        # Shift so that tokens < n predict n\n",
    "        shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "                \n",
    "        bsz, seq_length = shift_labels.size()\n",
    "        ####\n",
    "        shift_logits = shift_logits.reshape(-1, shift_logits.size(-1))\n",
    "        shift_labels = shift_labels.reshape(-1)\n",
    "        \n",
    "        bindex = torch.arange(shift_logits.shape[0]).to(shift_logits.device, \n",
    "                                                        non_blocking=False\n",
    "                                                       )\n",
    "        logits_correct = shift_logits[bindex, shift_labels.unsqueeze(0)]\n",
    "        cloned_logits = shift_logits.clone()\n",
    "        cloned_logits[bindex, shift_labels.unsqueeze(0)] = torch.tensor(-torch.inf, device=shift_logits.device, dtype=shift_logits.dtype)\n",
    "\n",
    "        margins = logits_correct - cloned_logits.logsumexp(dim=-1)\n",
    "        ####\n",
    "        margins = margins.reshape(bsz, seq_length)\n",
    "        padding_mask = (shift_labels!=-100).reshape(bsz, seq_length)\n",
    "        ####\n",
    "        margins = margins * padding_mask\n",
    "        loss = margins.sum(dim=1) / padding_mask.sum(dim=1)   \n",
    "    return loss.squeeze(0) # must be a scaler\n",
    "\n",
    "def vectorize_and_ignore_buffers(g, params_dict=None):\n",
    "    \"\"\"\n",
    "    gradients are given as a tuple :code:`(grad_w0, grad_w1, ... grad_wp)` where\n",
    "    :code:`p` is the number of weight matrices. each :code:`grad_wi` has shape\n",
    "    :code:`[batch_size, ...]` this function flattens :code:`g` to have shape\n",
    "    :code:`[batch_size, num_params]`.\n",
    "    \"\"\"\n",
    "    batch_size = len(g[0])\n",
    "    out = []\n",
    "    if params_dict is not None:\n",
    "        for b in range(batch_size):\n",
    "            out.append(torch.cat([x[b].flatten() for i, x in enumerate(g) if is_not_buffer(i, params_dict)]))\n",
    "    else:\n",
    "        for b in range(batch_size):\n",
    "            out.append(torch.cat([x[b].flatten() for x in g]))\n",
    "    return torch.stack(out)\n",
    "\n",
    "ft_compute_grad = grad(compute_loss)\n",
    "ft_compute_sample_grad = vmap(ft_compute_grad, \n",
    "                              in_dims=(None, None, 0, 0, 0),\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45bdd65-400f-4dea-8ee5-d1943cc7c47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67bad1ee-1bf5-489c-ad8d-b548586d104a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9307"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "proj_dim = johnson_lindenstrauss_min_dim(n_samples=len(train_dataset), eps=0.1) # 误差有点高\n",
    "proj_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08a97077-ae5e-4bb8-8b9d-f0b0d1be0c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9728"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_dim = (proj_dim//512+1)*512\n",
    "proj_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5fb32a4-2d4c-456d-ba9f-8ce1a1503888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trak.projectors import ProjectionType, AbstractProjector, CudaProjector\n",
    "projector = CudaProjector(grad_dim=16777216, \n",
    "                          proj_dim=proj_dim,\n",
    "                          seed=0, \n",
    "                          proj_type=ProjectionType.normal,\n",
    "                          # proj_type=ProjectionType.rademacher,\n",
    "                          device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b47ca8e-0c9d-4bd9-b3fe-240246c94128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6501"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17366876-184f-4f05-b64e-7687ec9ad4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efed3319-ce47-4751-85ba-a8690fa8cbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████████                  | 5174/6501 [58:34<14:51,  1.49it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 6501/6501 [1:13:42<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "set_seeds(42)\n",
    "model.eval()\n",
    "    \n",
    "params = {k: v.detach() for k, v in model.named_parameters() if v.requires_grad==True}\n",
    "buffers = {k: v.detach() for k, v in model.named_buffers() if v.requires_grad==True}\n",
    "        \n",
    "train_dstore_keys = np.memmap('./saved/train_keys.npy', \n",
    "                              dtype=np.float16, \n",
    "                              mode='w+', \n",
    "                              shape=(len(train_dataset), proj_dim))\n",
    "\n",
    "for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "    \n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    bsz = batch['labels'].shape[0]\n",
    "    # print(batch)\n",
    "    ft_per_sample_grads = ft_compute_sample_grad(params, buffers, batch['input_ids'], batch['attention_mask'], batch['labels'])\n",
    "    ft_per_sample_grads = vectorize_and_ignore_buffers(list(ft_per_sample_grads.values()))\n",
    "    ft_per_sample_grads = projector.project(ft_per_sample_grads, model_id=0)\n",
    "    \n",
    "    train_dstore_keys[step*batch_size:step*batch_size+bsz] = ft_per_sample_grads.detach().cpu().numpy()\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bcb3a5-f245-4760-b908-64f6f945650b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "827a13b6-5101-41fe-84cf-57bf37794032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([  3.127,   4.562,  23.12 , ..., -11.91 ,   2.809,   7.363],\n",
       "       dtype=float16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dstore_keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27d20748-4fe9-4caa-b16c-f24bad76048b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52002, 9728)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dstore_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e1444-af7d-4c92-916b-7f11c9625ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8c5de-a029-40de-a2ca-8d9435eaba36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
